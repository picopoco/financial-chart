{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   Bonus 1)\n",
    "**(Problem)** A serious bottleneck in the learning, for more complex environments, is the sample collection time. In train_PG.py, we only collect trajectories in a single thread, but this process can be fully parallelized across threads to get a useful speedup. Implement the parallelization and report on the difference in training time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 멀티프로세싱과 멀티스레딩의 개념과 관련 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 멀티프로세싱 구현 참조\n",
    "\n",
    "- https://github.com/joschu/modular_rl/blob/master/modular_rl/core.py\n",
    "-  https://github.com/joschu/modular_rl/blob/master/modular_rl/parallel_utils.py\n",
    "\n",
    "#### 멀티스레딩 구현 참조\n",
    "- A3C 예제들 (파이썬과 케라스로 배우는 강화학습(p.302~) 등)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   Bonus 2)\n",
    "**(Problem)** Implement GAE-λ for advantage estimation. Run experiments in a MuJoCo gym environment to explore whether this speeds up training. (Walker2d-v1 may be good for this.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GAE(Generalized Advantage Estimation)의 개념"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 지난 학기 수업 : http://rll.berkeley.edu/deeprlcoursesp17/docs/lec6.pdf\n",
    "\n",
    "- 원문: https://arxiv.org/abs/1506.02438\n",
    "- We propose a family of policy gradient estimators that significantly reduce variance while maintaining a tolerable level of bias. We call this estimation scheme, parameterized by γ ∈ [0, 1] and λ ∈ [0, 1], the generalized advantage estimator (GAE)\n",
    "- The generalized advantage estimator GAE(γ, λ) is defined as the exponentially-weighted average of these k-step estimators:\n",
    "- The generalized advantage estimator for 0 < λ < 1 makes a compromise between bias and variance, controlled by parameter λ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GAE Performance\n",
    "https://arxiv.org/abs/1506.02438"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### GAE 구현\n",
    ": train_pg.py 파일에 lambda 파라미터 추가 --> train_pg_gae.py (56, 352, 48, 482행)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   Bonus 3)\n",
    "**(Problem)** In PG, we collect a batch of data, estimate a single gradient, and then discard the data and move on. Can we potentially accelerate PG by taking multiple gradient descent steps with the same batch of data? Explore this option and report on your results. Set up a fair comparison between single-step PG and multi-step PG on at least one MuJoCo gym environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Policy Gradient는 On-policy 방법론이다!**\n",
    "- We throw out each batch of data immediately after just one gradient step \n",
    "- Why? **PG is an on-policy expectation**\n",
    "\n",
    "http://rll.berkeley.edu/deeprlcourse/f17docs/lecture_13_advanced_pg.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On-policy vs Off-policy\n",
    "\n",
    "##### On-policy\n",
    "\n",
    "- 학습하는 policy와 행동하는 policy가 반드시 같아야만 학습이 가능한 강화학습 알고리즘.\n",
    "- ex) Sarsa, PG\n",
    "- on-policy의 경우 1번이라도 학습을 해서 policy improvement를 시킨 순간, 그 policy가 했던 과거의 experience들은 모두 사용이 불가능하다. 즉 매우 데이터 효율성이 떨어진다. 바로바로 exploration해서 학습하고 재사용이 불가능하다.\n",
    "\n",
    "\n",
    "##### Off-policy\n",
    "- 학습하는 policy와 행동하는 policy가 반드시 같지 않아도 학습(따로 따로 학습)이 가능한 알고리즘.\n",
    "- ex) Q-learning\n",
    "- off-policy는 현재 학습하는 policy가 과거에 했던 experience도 학습에 사용이 가능하고, 심지어는 해당 policy가 아니라 예를 들어 사람이 한 데이터로부터도 학습을 시킬 수가 있다.\n",
    "\n",
    "출처: http://newsight.tistory.com/250 [New Sight]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}